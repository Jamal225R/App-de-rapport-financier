import os
import streamlit as st
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain_core.vectorstores import InMemoryVectorStore
from langchain_openai import OpenAIEmbeddings, OpenAI
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Charger les variables d‚Äôenvironnement depuis le fichier .env
load_dotenv()

# R√©cup√©rer la cl√© API OpenAI
openai_api_key = os.getenv("OPENAI_API_KEY")

# V√©rifier que la cl√© API est bien r√©cup√©r√©e
if not openai_api_key:
    st.error("‚ùå Erreur : La cl√© API OpenAI n'est pas d√©finie. V√©rifiez votre fichier .env.")
    st.stop()  # Arr√™te l'ex√©cution si la cl√© est absente

# Interface Streamlit
st.title("üîç Analyse de Rapports Juridiques avec LangChain")

# Chargement du fichier PDF
uploaded_file = st.file_uploader("üìÇ T√©l√©chargez un rapport juridique (PDF)", type="pdf")

if uploaded_file is not None:
    st.write("üìÑ **Fichier charg√© :**", uploaded_file.name)

    # Sauvegarder temporairement le fichier
    with open("temp.pdf", "wb") as f:
        f.write(uploaded_file.getbuffer())

    # Extraction du texte
    loader = PyPDFLoader("temp.pdf")
    pages = loader.load()

    # V√©rifier si des pages ont √©t√© extraites
    if not pages:
        st.error("‚ùå Impossible de lire le fichier PDF. V√©rifiez qu'il contient du texte lisible.")
        st.stop()

    # Diviser le texte en segments pour analyse
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    texts = text_splitter.split_documents(pages)

    # V√©rifier si du texte a √©t√© extrait
    if not texts:
        st.error("‚ùå Aucune donn√©e textuelle n'a pu √™tre extraite.")
        st.stop()

    # Afficher un extrait du texte
    st.subheader("üìú Aper√ßu du document :")
    st.write(texts[0].page_content)  # Affiche un extrait

    # Embedding avec OpenAI
    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
    vector_store = InMemoryVectorStore.from_documents(texts, embeddings)

    # Syst√®me de recherche
    query = st.text_input("üîç Posez une question sur le document üìñ")
    if query:
        results = vector_store.similarity_search(query, k=3)
        
        if results:
            st.subheader("üìå R√©sultats les plus pertinents :")
            for i, res in enumerate(results):
                st.write(f"üîπ **Extrait {i+1}** : {res.page_content}")
        else:
            st.warning("‚ö†Ô∏è Aucun r√©sultat trouv√© pour cette requ√™te.")
     # Questions financi√®res par d√©faut
        st.subheader("Questions pr√©d√©finies")
        default_questions = [
            "Quel est le chiffre d'affaires total de cette ann√©e ?",
            "Quels sont les segments les plus performants ?",
            "Quelle est l'√©volution des b√©n√©fices par rapport √† l'ann√©e pr√©c√©dente ?",
            "Quels sont les principaux co√ªts op√©rationnels ?",
            "Quel est le ratio de solvabilit√© (CET1) ?",
        ]
        selected_question = st.selectbox("Choisissez une question pr√©d√©finie :", default_questions)

        # Bouton pour les questions pr√©d√©finies
        if st.button("Obtenir une r√©ponse pour la question pr√©d√©finie"):
            st.write("üîç Recherche en cours pour la question pr√©d√©finie...")
            docs = vector_store.similarity_search(selected_question, k=2)
            if docs:
                for doc in docs:
                    st.write(f'Page {doc.metadata["page"]}: {doc.page_content[:300]}...')
            else:
                st.warning("‚ö†Ô∏è Aucune r√©ponse trouv√©e dans le document.")

        # Option pour poser une question personnalis√©e
        st.subheader("Posez une question sp√©cifique")
        user_question = st.text_input("Entrez votre propre question :", "")

        # Bouton pour les questions sp√©cifiques
        if st.button("Obtenir une r√©ponse pour la question sp√©cifique"):
            if user_question.strip():
                st.write("üîç Recherche en cours pour la question sp√©cifique...")
                docs = vector_store.similarity_search(user_question, k=2)
                if docs:
                    for doc in docs:
                        st.write(f'Page {doc.metadata["page"]}: {doc.page_content[:300]}...')
                else:
                    st.warning("‚ö†Ô∏è Aucune r√©ponse trouv√©e dans le document.")
            else:
                st.warning("‚ö†Ô∏è Veuillez entrer une question sp√©cifique avant de cliquer.")